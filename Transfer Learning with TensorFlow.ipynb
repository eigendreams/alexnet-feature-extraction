{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with TensorFlow\n",
    "\n",
    "*Transfer learning* is the practice of starting with a network that has already been trained, and then applying that network to your own problem.\n",
    "\n",
    "Because neural networks can often take days or even weeks to train, transfer learning (i.e. starting with a network that somebody else has already spent a lot of time training) can greatly shorten training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "In order to complete this lab, install Python 3, tensorflow, numpy, scipy, matplotlib, and pillow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet\n",
    "Here, you're going to practice transfer learning with [AlexNet](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiG34CS7vHPAhVKl1QKHW2JAJkQFggcMAA&url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf&usg=AFQjCNFlGsSmTUkJw0gLJ0Ry4cm961B7WA&bvm=bv.136593572,d.cGw).\n",
    "\n",
    "AlexNet is a popular base network for transfer learning because its structure is relatively straightforward, it's not too big, and it performs well empirically.\n",
    "\n",
    "Here is a TensorFlow implementation of AlexNet (adapted from [Michael Guerhoy and Davi Frossard](http://www.cs.toronto.edu/~guerzhoy/tf_alexnet/)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import os\n",
    "from pylab import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "import time\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.ndimage import filters\n",
    "import urllib\n",
    "from numpy import random\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "train_x = zeros((1, 227,227,3)).astype(float32)\n",
    "train_y = zeros((1, 1000))\n",
    "xdim = train_x.shape[1:]\n",
    "ydim = train_y.shape[1]\n",
    "\n",
    "net_data = load(\"bvlc-alexnet.npy\", encoding=\"latin1\").item()\n",
    "\n",
    "def conv(input, kernel, biases, k_h, k_w, c_o, s_h, s_w,  padding=\"VALID\", group=1):\n",
    "    '''From https://github.com/ethereon/caffe-tensorflow\n",
    "    '''\n",
    "    c_i = input.get_shape()[-1]\n",
    "    assert c_i%group==0\n",
    "    assert c_o%group==0\n",
    "    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n",
    "    \n",
    "    \n",
    "    if group==1:\n",
    "        conv = convolve(input, kernel)\n",
    "    else:\n",
    "        input_groups = tf.split(3, group, input)\n",
    "        kernel_groups = tf.split(3, group, kernel)\n",
    "        output_groups = [convolve(i, k) for i,k in zip(input_groups, kernel_groups)]\n",
    "        conv = tf.concat(3, output_groups)\n",
    "    return  tf.reshape(tf.nn.bias_add(conv, biases), [-1]+conv.get_shape().as_list()[1:])\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None,) + xdim)\n",
    "resized = tf.image.resize_images(x, (227, 227))\n",
    "\n",
    "def features():\n",
    "\n",
    "    #conv1\n",
    "    #conv(11, 11, 96, 4, 4, padding='VALID', name='conv1')\n",
    "    k_h = 11; k_w = 11; c_o = 96; s_h = 4; s_w = 4\n",
    "    conv1W = tf.Variable(net_data[\"conv1\"][0])\n",
    "    conv1b = tf.Variable(net_data[\"conv1\"][1])\n",
    "    conv1_in = conv(resized, conv1W, conv1b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=1)\n",
    "    conv1 = tf.nn.relu(conv1_in)\n",
    "\n",
    "    #lrn1\n",
    "    #lrn(2, 2e-05, 0.75, name='norm1')\n",
    "    radius = 2; alpha = 2e-05; beta = 0.75; bias = 1.0\n",
    "    lrn1 = tf.nn.local_response_normalization(conv1,\n",
    "                                                      depth_radius=radius,\n",
    "                                                      alpha=alpha,\n",
    "                                                      beta=beta,\n",
    "                                                      bias=bias)\n",
    "\n",
    "    #maxpool1\n",
    "    #max_pool(3, 3, 2, 2, padding='VALID', name='pool1')\n",
    "    k_h = 3; k_w = 3; s_h = 2; s_w = 2; padding = 'VALID'\n",
    "    maxpool1 = tf.nn.max_pool(lrn1, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
    "\n",
    "\n",
    "    #conv2\n",
    "    #conv(5, 5, 256, 1, 1, group=2, name='conv2')\n",
    "    k_h = 5; k_w = 5; c_o = 256; s_h = 1; s_w = 1; group = 2\n",
    "    conv2W = tf.Variable(net_data[\"conv2\"][0])\n",
    "    conv2b = tf.Variable(net_data[\"conv2\"][1])\n",
    "    conv2_in = conv(maxpool1, conv2W, conv2b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "    conv2 = tf.nn.relu(conv2_in)\n",
    "\n",
    "\n",
    "    #lrn2\n",
    "    #lrn(2, 2e-05, 0.75, name='norm2')\n",
    "    radius = 2; alpha = 2e-05; beta = 0.75; bias = 1.0\n",
    "    lrn2 = tf.nn.local_response_normalization(conv2,\n",
    "                                                      depth_radius=radius,\n",
    "                                                      alpha=alpha,\n",
    "                                                      beta=beta,\n",
    "                                                      bias=bias)\n",
    "\n",
    "    #maxpool2\n",
    "    #max_pool(3, 3, 2, 2, padding='VALID', name='pool2')                                                  \n",
    "    k_h = 3; k_w = 3; s_h = 2; s_w = 2; padding = 'VALID'\n",
    "    maxpool2 = tf.nn.max_pool(lrn2, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
    "\n",
    "    #conv3\n",
    "    #conv(3, 3, 384, 1, 1, name='conv3')\n",
    "    k_h = 3; k_w = 3; c_o = 384; s_h = 1; s_w = 1; group = 1\n",
    "    conv3W = tf.Variable(net_data[\"conv3\"][0])\n",
    "    conv3b = tf.Variable(net_data[\"conv3\"][1])\n",
    "    conv3_in = conv(maxpool2, conv3W, conv3b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "    conv3 = tf.nn.relu(conv3_in)\n",
    "\n",
    "    #conv4\n",
    "    #conv(3, 3, 384, 1, 1, group=2, name='conv4')\n",
    "    k_h = 3; k_w = 3; c_o = 384; s_h = 1; s_w = 1; group = 2\n",
    "    conv4W = tf.Variable(net_data[\"conv4\"][0])\n",
    "    conv4b = tf.Variable(net_data[\"conv4\"][1])\n",
    "    conv4_in = conv(conv3, conv4W, conv4b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "    conv4 = tf.nn.relu(conv4_in)\n",
    "\n",
    "\n",
    "    #conv5\n",
    "    #conv(3, 3, 256, 1, 1, group=2, name='conv5')\n",
    "    k_h = 3; k_w = 3; c_o = 256; s_h = 1; s_w = 1; group = 2\n",
    "    conv5W = tf.Variable(net_data[\"conv5\"][0])\n",
    "    conv5b = tf.Variable(net_data[\"conv5\"][1])\n",
    "    conv5_in = conv(conv4, conv5W, conv5b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "    conv5 = tf.nn.relu(conv5_in)\n",
    "\n",
    "    #maxpool5\n",
    "    #max_pool(3, 3, 2, 2, padding='VALID', name='pool5')\n",
    "    k_h = 3; k_w = 3; s_h = 2; s_w = 2; padding = 'VALID'\n",
    "    maxpool5 = tf.nn.max_pool(conv5, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
    "\n",
    "    #fc6\n",
    "    #fc(4096, name='fc6')\n",
    "    fc6W = tf.Variable(net_data[\"fc6\"][0])\n",
    "    fc6b = tf.Variable(net_data[\"fc6\"][1])\n",
    "    fc6 = tf.nn.relu_layer(tf.reshape(maxpool5, [-1, int(prod(maxpool5.get_shape()[1:]))]), fc6W, fc6b)\n",
    "\n",
    "    #fc7\n",
    "    #fc(4096, name='fc7')\n",
    "    fc7W = tf.Variable(net_data[\"fc7\"][0])\n",
    "    fc7b = tf.Variable(net_data[\"fc7\"][1])\n",
    "    fc7 = tf.nn.relu_layer(fc6, fc7W, fc7b)\n",
    "    return fc7\n",
    "\n",
    "def logits():\n",
    "    #fc8\n",
    "    #fc(1000, relu=False, name='fc8')\n",
    "    fc8W = tf.Variable(net_data[\"fc8\"][0])\n",
    "    fc8b = tf.Variable(net_data[\"fc8\"][1])\n",
    "    fc8 = tf.nn.xw_plus_b(features(), fc8W, fc8b)\n",
    "    return fc8\n",
    "\n",
    "def probabilities():\n",
    "    #prob\n",
    "    #softmax(name='prob'))\n",
    "    return tf.nn.softmax(logits())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageNet Inference\n",
    "\n",
    "![alt text](poodle.png \"Poodle\")\n",
    "![alt text](weasel.png \"Weasel\")\n",
    "\n",
    "To start, run a few ImageNet images through the network, and verify that the network classifies them correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# NOTE: You don\\'t need to edit this code.\\n\\nfrom caffe_classes import class_names\\n\\n# Initialize the Model\\nprob = probabilities()\\ninit = tf.initialize_all_variables()\\nsess = tf.Session()\\nsess.run(init)\\n\\n# Read Images\\nim1 = (imread(\"poodle.png\")[:,:,:3]).astype(float32)\\nim1 = im1 - mean(im1)\\n\\nim2 = (imread(\"weasel.png\")[:,:,:3]).astype(float32)\\nim2 = im2 - mean(im2)\\n\\n# Run Inference\\nt = time.time()\\noutput = sess.run(prob, feed_dict = {x:[im1,im2]})\\n\\n# Print Output\\nfor input_im_ind in range(output.shape[0]):\\n    inds = argsort(output)[input_im_ind,:]\\n    print(\"Image\", input_im_ind)\\n    for i in range(5):\\n        print(\"%s: %.3f\" % (class_names[inds[-1-i]], output[input_im_ind, inds[-1-i]]))\\n    print()\\n\\nprint(\"Time: %.3f seconds\" % (time.time()-t))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# NOTE: You don't need to edit this code.\n",
    "\n",
    "from caffe_classes import class_names\n",
    "\n",
    "# Initialize the Model\n",
    "prob = probabilities()\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Read Images\n",
    "im1 = (imread(\"poodle.png\")[:,:,:3]).astype(float32)\n",
    "im1 = im1 - mean(im1)\n",
    "\n",
    "im2 = (imread(\"weasel.png\")[:,:,:3]).astype(float32)\n",
    "im2 = im2 - mean(im2)\n",
    "\n",
    "# Run Inference\n",
    "t = time.time()\n",
    "output = sess.run(prob, feed_dict = {x:[im1,im2]})\n",
    "\n",
    "# Print Output\n",
    "for input_im_ind in range(output.shape[0]):\n",
    "    inds = argsort(output)[input_im_ind,:]\n",
    "    print(\"Image\", input_im_ind)\n",
    "    for i in range(5):\n",
    "        print(\"%s: %.3f\" % (class_names[inds[-1-i]], output[input_im_ind, inds[-1-i]]))\n",
    "    print()\n",
    "\n",
    "print(\"Time: %.3f seconds\" % (time.time()-t))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic Sign Inference\n",
    "![alt text](construction.jpg \"Construction Sign\")\n",
    "![alt text](stop.jpg \"Stop Sign\")\n",
    "\n",
    "Next, run two of the traffic sign images through the network, and see how well the classifier performs.\n",
    "\n",
    "You'll notice, however, that the AlexNet model expects a 227x227x3 pixel image, whereas the traffic sign images are 32x32x3 pixels.\n",
    "\n",
    "In order to feed our the traffic sign images into AlexNet, you'll need to resize the images to the dimensions that AlexNet expects.\n",
    "\n",
    "You could resize the images outside of this program, but that would make for a huge collection of images. Instead, use the `tf.images.resize_images()` method to resize the images within the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom caffe_classes import class_names\\n\\n# TODO: Update the xdim, x, and resized variables to accomodate 32x32x3 pixel images.\\ntrain_x = zeros((1, 32,32,3)).astype(float32)\\nxdim = train_x.shape[1:]\\nx = tf.placeholder(tf.float32, (None,) + xdim)\\nresized = tf.image.resize_images(x, (227, 227))\\n\\n# NOTE: You don\\'t need to edit the code below.\\n# Initialize the Model\\nprob = probabilities()\\ninit = tf.initialize_all_variables()\\nsess = tf.Session()\\nsess.run(init)\\n\\n# Read Images\\nim1 = (imread(\"construction.jpg\")[:,:,:3]).astype(float32)\\nim1 = im1 - mean(im1)\\n\\nim2 = (imread(\"stop.jpg\")[:,:,:3]).astype(float32)\\nim2 = im2 - mean(im2)\\n\\n# Run Inference\\nt = time.time()\\noutput = sess.run(prob, feed_dict = {x:[im1,im2]})\\n\\n# Print Output\\nfor input_im_ind in range(output.shape[0]):\\n    inds = argsort(output)[input_im_ind,:]\\n    print(\"Image\", input_im_ind)\\n    for i in range(5):\\n        print(\"%s: %.3f\" % (class_names[inds[-1-i]], output[input_im_ind, inds[-1-i]]))\\n    print()\\n\\nprint(\"Time: %.3f seconds\" % (time.time()-t))\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from caffe_classes import class_names\n",
    "\n",
    "# TODO: Update the xdim, x, and resized variables to accomodate 32x32x3 pixel images.\n",
    "train_x = zeros((1, 32,32,3)).astype(float32)\n",
    "xdim = train_x.shape[1:]\n",
    "x = tf.placeholder(tf.float32, (None,) + xdim)\n",
    "resized = tf.image.resize_images(x, (227, 227))\n",
    "\n",
    "# NOTE: You don't need to edit the code below.\n",
    "# Initialize the Model\n",
    "prob = probabilities()\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Read Images\n",
    "im1 = (imread(\"construction.jpg\")[:,:,:3]).astype(float32)\n",
    "im1 = im1 - mean(im1)\n",
    "\n",
    "im2 = (imread(\"stop.jpg\")[:,:,:3]).astype(float32)\n",
    "im2 = im2 - mean(im2)\n",
    "\n",
    "# Run Inference\n",
    "t = time.time()\n",
    "output = sess.run(prob, feed_dict = {x:[im1,im2]})\n",
    "\n",
    "# Print Output\n",
    "for input_im_ind in range(output.shape[0]):\n",
    "    inds = argsort(output)[input_im_ind,:]\n",
    "    print(\"Image\", input_im_ind)\n",
    "    for i in range(5):\n",
    "        print(\"%s: %.3f\" % (class_names[inds[-1-i]], output[input_im_ind, inds[-1-i]]))\n",
    "    print()\n",
    "\n",
    "print(\"Time: %.3f seconds\" % (time.time()-t))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "The problem is that AlexNet was trained on the [ImageNet](http://www.image-net.org/) database, which has 1000 classes of images. You can see the classes in the `caffe_classes.py` file. None of those classes involves traffic signs.\n",
    "\n",
    "In order to successfully classify our traffic sign images, you need to remove the final, 1000-neuron classification layer and replace it with a new, 43-neuron classification layer.\n",
    "\n",
    "This is called feature extraction, because you're basically extracting the images features captured by the penultimate layer, and passing them to a new classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# NOTE: You don\\'t need to edit the code below.\\n# Initialize the Model\\nprob = probabilities()\\ninit = tf.initialize_all_variables()\\nsess = tf.Session()\\nsess.run(init)\\n\\n# Read Images\\nim1 = (imread(\"construction.jpg\")[:,:,:3]).astype(float32)\\nim1 = im1 - mean(im1)\\n\\nim2 = (imread(\"stop.jpg\")[:,:,:3]).astype(float32)\\nim2 = im2 - mean(im2)\\n\\n# Run Inference\\nt = time.time()\\noutput = sess.run(prob, feed_dict = {x:[im1,im2]})\\n\\n# Print Output\\nfor input_im_ind in range(output.shape[0]):\\n    inds = argsort(output)[input_im_ind,:]\\n    print(\"Image\", input_im_ind)\\n    for i in range(5):\\n        print(\"%s: %.3f\" % (inds[-1-i], output[input_im_ind, inds[-1-i]]))\\n    print()\\n\\nprint(\"Time: %.3f seconds\" % (time.time()-t))\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Redefine the logits() function to create a new fully-connected layer.\n",
    "def logits():\n",
    "    #fc8\n",
    "    #fc(1000, relu=False, name='fc8')\n",
    "    num_inputs  = 4096\n",
    "    num_outputs = 43\n",
    "    shape       = [num_inputs, num_outputs]\n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "    biases  = tf.Variable(tf.constant(0.05, shape=[num_outputs]))\n",
    "    layer   = tf.nn.xw_plus_b(features(), weights, biases)\n",
    "    return layer\n",
    "    #fc8W = tf.Variable(net_data[\"fc8\"][0])\n",
    "    #fc8b = tf.Variable(net_data[\"fc8\"][1])\n",
    "    #fc8 = tf.nn.xw_plus_b(features(), fc8W, fc8b)\n",
    "    #return fc8\n",
    "\"\"\"\n",
    "# NOTE: You don't need to edit the code below.\n",
    "# Initialize the Model\n",
    "prob = probabilities()\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Read Images\n",
    "im1 = (imread(\"construction.jpg\")[:,:,:3]).astype(float32)\n",
    "im1 = im1 - mean(im1)\n",
    "\n",
    "im2 = (imread(\"stop.jpg\")[:,:,:3]).astype(float32)\n",
    "im2 = im2 - mean(im2)\n",
    "\n",
    "# Run Inference\n",
    "t = time.time()\n",
    "output = sess.run(prob, feed_dict = {x:[im1,im2]})\n",
    "\n",
    "# Print Output\n",
    "for input_im_ind in range(output.shape[0]):\n",
    "    inds = argsort(output)[input_im_ind,:]\n",
    "    print(\"Image\", input_im_ind)\n",
    "    for i in range(5):\n",
    "        print(\"%s: %.3f\" % (inds[-1-i], output[input_im_ind, inds[-1-i]]))\n",
    "    print()\n",
    "\n",
    "print(\"Time: %.3f seconds\" % (time.time()-t))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Feature Extractor\n",
    "The feature extractor you just created works, in the sense that data will flow through the network and result in predictions.\n",
    "\n",
    "But the predictions aren't accurate, because you haven't yet trained the new classification layer.\n",
    "\n",
    "In order to do that, you'll need to read in the training dataset and train the network with cross entropy.\n",
    "\n",
    "Notice that in the network definition (look in the `features()` function), all of the layers are set to `trainable=False`. This freezes the weights of those layers, so you keep the trained AlexNet features and only train the final classification layer. This also makes training faster.\n",
    "\n",
    "Training AlexNet (even just the final layer!) can take a little while, so it can be helpful to try out your code using only a small portion of the training set. Once you're confident your implementation works, you can train use the entire training dataset to train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Load the training dataset.\n",
    "\n",
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# TODO: fill this in based on where you saved the training and testing data\n",
    "training_file = 'train.p'\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "X_train, y_train = train['features'], train['labels']\n",
    "assert(X_train.shape[0] == y_train.shape[0]), \"The number of images is not equal to the number of labels.\"\n",
    "assert(X_train.shape[1:] == (32,32,3)), \"The dimensions of the images are not 32 x 32 x 3.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Pre-process the input data.\n",
    "# TODO: Implement data normalization here.\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def normalize_greyscale(image_data):\n",
    "    x_min = np.min(image_data)\n",
    "    x_max = np.max(image_data)\n",
    "    a     = -0.5\n",
    "    b     = 0.5\n",
    "    return a + np.divide( (image_data - x_min ) * ( b - a), x_max - x_min) \n",
    "\n",
    "def preprocess_all_images(X_train, img_size):\n",
    "    # Preallocate space for all images, for just a few tens of thousands of \n",
    "    # small images this should not need advanced caching techniques\n",
    "    n_train = X_train.shape[0]\n",
    "    train_features = np.zeros( [n_train, img_size, img_size, 3] )\n",
    "    for i in range(n_train):\n",
    "        train_features[i,] = normalize_greyscale(X_train[i])\n",
    "    return train_features\n",
    "\n",
    "X_train = preprocess_all_images(X_train, 32)\n",
    "assert(round(np.mean(X_train)) == 0), \"The mean of the input data is: %f\" % np.mean(X_train)\n",
    "assert(np.min(X_train) == -0.5 and np.max(X_train) == 0.5), \"The range of the input data is: %.1f to %.1f\" % (np.min(X_train), np.max(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Once you are confident that the training works, update the training set to use all of the data.\n",
    "# TODO: Compile and train the model to measure validation accuracy.\n",
    "def random_batch(Image_train, labels_train, batch_size):\n",
    "    # Number of images in the training-set.\n",
    "    num_images = len(Image_train)\n",
    "    # Create a random index.\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=batch_size,\n",
    "                           replace=False)\n",
    "    # Use the random index to select random images and labels.\n",
    "    features_batch = Image_train[idx, :]\n",
    "    labels_batch   = labels_train[idx]\n",
    "\n",
    "    return features_batch, labels_batch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(y_train)\n",
    "Y_train = encoder.transform(y_train)\n",
    "Y_train = Y_train.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = zeros((1, 32,32,3)).astype(float32)\n",
    "xdim    = train_x.shape[1:]\n",
    "x       = tf.placeholder(tf.float32, (None,) + xdim)\n",
    "resized = tf.image.resize_images(x, (227, 227))\n",
    "\n",
    "num_classes = 43\n",
    "y_true      = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls  = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "layer_logits       = logits()\n",
    "y_pred             = tf.nn.softmax(layer_logits)\n",
    "y_pred_cls         = tf.argmax(y_pred, dimension=1)\n",
    "cross_entropy      = tf.nn.softmax_cross_entropy_with_logits(logits=layer_logits, labels=y_true)\n",
    "cost               = tf.reduce_mean(cross_entropy)\n",
    "optimizer          = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saver for ease of retraining\n",
    "saver = tf.train.Saver(max_to_keep=10)\n",
    "save_dir = 'checkpoints/'\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "save_path = save_dir + 'alexnet_transfer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Train the network.\n",
    "# Taken from Hvass Labs, with minor modifications, as it is vastly \n",
    "# easier to define the network this way\n",
    "# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n",
    "\n",
    "from datetime import timedelta\n",
    "import time\n",
    "\n",
    "train_batch_size = 2\n",
    "\n",
    "def optimize(num_iterations):\n",
    "\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time     = time.time()\n",
    "    end_batch_time = start_time\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        start_batch_time = end_batch_time\n",
    "\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        x_batch, y_true_batch = random_batch(X_train, Y_train, train_batch_size)\n",
    "\n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        # We also want to retrieve the global_step counter.\n",
    "        sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        # Print status every 100 iterations and after last iteration.\n",
    "        if (i % 100 == 0) or (i == (num_iterations - 1)):\n",
    "\n",
    "            end_batch_time = time.time()\n",
    "            \n",
    "            # Calculate the accuracy on the training-batch.\n",
    "            acc_train = sess.run(accuracy, feed_dict=feed_dict_train)\n",
    "            \n",
    "            time_batch_dif = end_batch_time - start_batch_time\n",
    "            \n",
    "            # Message for printing.\n",
    "            msg = \"Global Step: {0:>6}, Training Batch Accuracy: {1:>6.1%}\"\n",
    "            print(msg.format(i, acc_train))\n",
    "            print(\"Steps time usage: \" + str(timedelta(seconds=int(round(time_batch_dif)))))\n",
    "            \n",
    "        # Save a checkpoint to disk every 1000 iterations (and last).\n",
    "        if (i % 1000 == 0) or (i == num_iterations - 1):\n",
    "            # Save all variables of the TensorFlow graph to a\n",
    "            # checkpoint. Append the global_step counter\n",
    "            # to the filename so we save the last several checkpoints.\n",
    "            #saver.save(sess,\n",
    "            #           save_path=save_path)\n",
    "\n",
    "            #print(\"Saved checkpoint.\")\n",
    "            ;\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Total time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:      0, Training Batch Accuracy: 100.0%\n",
      "Steps time usage: 0:00:01\n",
      "Global Step:    100, Training Batch Accuracy:   0.0%\n",
      "Steps time usage: 0:00:58\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation Accuracy:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "You've trained AlexNet as a feature extractor!\n",
    "\n",
    "Don't be discouraged if your validation accuracy still isn't as high as you'd like.\n",
    "\n",
    "Coming up, you'll explore other networks to use for transfer learning, as well as approaches to improve accuracy."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:AlexNet]",
   "language": "python",
   "name": "conda-env-AlexNet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
